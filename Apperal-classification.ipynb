{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory of dataset: C:/Users/Kaushik/Desktop/anacondaDocs/analytics-vidhya-apperal problem/\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"C:/Users/Kaushik/Desktop/anacondaDocs/analytics-vidhya-apperal problem/\"\n",
    "print(\"directory of dataset:\",input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device training on: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available:\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "print(\"device training on:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1      9\n",
       "1   2      0\n",
       "2   3      0\n",
       "3   4      3\n",
       "4   5      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(input_dir+\"train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id\n",
       "0  60001\n",
       "1  60002\n",
       "2  60003\n",
       "3  60004\n",
       "4  60005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(input_dir+\"test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class apperal_dataset(Dataset):\n",
    "    def __init__(self, df, folder, transforms, labels):\n",
    "        self.df = df\n",
    "        self.folder = folder\n",
    "        self.transforms = transforms\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_id = str(self.df.loc[idx,\"id\"])\n",
    "        img_src = input_dir +self.folder +\"/\" +img_id + \".png\"\n",
    "        image = cv2.imread(img_src,cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = torch.from_numpy(image)\n",
    "        image = image.to(dtype=torch.float)\n",
    "        if(self.labels):\n",
    "            labels = torch.tensor(self.df.loc[idx,\"label\"])\n",
    "            return image, labels\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = apperal_dataset(df=train_df, folder=\"train\", transforms = transform,labels=True)\n",
    "testset= apperal_dataset(df=test_df, folder=\"test\", transforms = transform,labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "validation_size = 0.2\n",
    "\n",
    "number_of_training_data = len(trainset)\n",
    "indices = list(range(number_of_training_data))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(validation_size * number_of_training_data))\n",
    "train_idx, validation_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(validation_idx)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers = num_workers)\n",
    "validation_loader = DataLoader(trainset, batch_size=BATCH_SIZE, sampler=valid_sampler, num_workers = num_workers)\n",
    "test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2352,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n",
      "classifier(\n",
      "  (fc1): Linear(in_features=2352, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = classifier()\n",
    "\n",
    "if torch.cuda.is_available:\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = cpu\n",
    "print(\"using device:\",device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.934949 \tValidation Loss: 0.105466\n",
      "Validation loss decreased (inf --> 0.105466).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.377328 \tValidation Loss: 0.085758\n",
      "Validation loss decreased (0.105466 --> 0.085758).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.339656 \tValidation Loss: 0.081989\n",
      "Validation loss decreased (0.085758 --> 0.081989).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.322728 \tValidation Loss: 0.097350\n",
      "Epoch: 5 \tTraining Loss: 0.327373 \tValidation Loss: 0.083581\n",
      "Epoch: 6 \tTraining Loss: 0.322819 \tValidation Loss: 0.083441\n",
      "Epoch: 7 \tTraining Loss: 0.328432 \tValidation Loss: 0.087111\n",
      "Epoch: 8 \tTraining Loss: 0.321784 \tValidation Loss: 0.089520\n",
      "Epoch: 9 \tTraining Loss: 0.323672 \tValidation Loss: 0.081524\n",
      "Validation loss decreased (0.081989 --> 0.081524).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.322314 \tValidation Loss: 0.082907\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 10\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() # prep model for training\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval() # prep model for evaluation\n",
    "    for data, target in validation_loader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update running validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(validation_loader.dataset)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        valid_loss\n",
    "        ))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        valid_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "submission_file = pd.read_csv(\"sample_submission_I5njJSF (1).csv\")\n",
    "submission_file.head()\n",
    "print(len(submission_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "\n",
    "model.eval()\n",
    "test_preds = None\n",
    "for data in test_loader:\n",
    "    outputs = model(data)\n",
    "    if test_preds is None:\n",
    "        test_preds = outputs.data.cpu()\n",
    "    else:\n",
    "        test_preds = torch.cat((test_preds, outputs.data.cpu()), dim=0)\n",
    "        \n",
    "_, preds = torch.max(test_preds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 2, 1,  ..., 8, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file[\"label\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.to_csv('submission_file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
